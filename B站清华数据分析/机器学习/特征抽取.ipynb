{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5905d397",
   "metadata": {},
   "source": [
    "## 为什么要进行特征抽取\n",
    "### 比如决策树算法，只能接收数字进行训练，这时候就要对特征值为str类型的数据进行特征抽取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "03a18cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdac921",
   "metadata": {},
   "source": [
    "### 字典抽取DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4ea3d7b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fruit</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>苹果</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>橘子</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>波萝</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>黄瓜</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>火龙果</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fruit  price\n",
       "0    苹果    5.0\n",
       "1    橘子    5.9\n",
       "2    波萝    9.9\n",
       "3    黄瓜    2.5\n",
       "4   火龙果   12.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruits=[{\"fruit\":\"苹果\",\"price\":5,\"eva\":\"cheap\"}, {\"fruit\":\"橘子\",\"price\":5.9,\"eva\":\"cheap\"}, {\"fruit\":\"波萝\",\"price\":9.9,\"eva\":\"expensive\"}, {\"fruit\":\"黄瓜\",\"price\":2.5,\"eva\":\"cheap\"}, {\"fruit\":\"火龙果\",\"price\":12,\"eva\":\"expensive\"}]\n",
    "fruits = pd.DataFrame(fruits)\n",
    "\n",
    "features = fruits.drop(\"eva\", axis=1)\n",
    "target = fruits[\"eva\"]\n",
    "\n",
    "# 对于feature values需要将其进行特征抽取\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4557d205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先转为字典类型\n",
    "features_pre = features.to_dict(orient=\"record\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "409bf66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fruit=橘子', 'fruit=波萝', 'fruit=火龙果', 'fruit=苹果', 'fruit=黄瓜', 'price']\n",
      "  (0, 3)\t1.0\n",
      "  (0, 5)\t5.0\n",
      "  (1, 0)\t1.0\n",
      "  (1, 5)\t5.9\n",
      "  (2, 1)\t1.0\n",
      "  (2, 5)\t9.9\n",
      "  (3, 4)\t1.0\n",
      "  (3, 5)\t2.5\n",
      "  (4, 2)\t1.0\n",
      "  (4, 5)\t12.0\n",
      "[[ 0.   0.   0.   1.   0.   5. ]\n",
      " [ 1.   0.   0.   0.   0.   5.9]\n",
      " [ 0.   1.   0.   0.   0.   9.9]\n",
      " [ 0.   0.   0.   0.   1.   2.5]\n",
      " [ 0.   0.   1.   0.   0.  12. ]]\n"
     ]
    }
   ],
   "source": [
    "# 特征抽取\n",
    "vect = sklearn.feature_extraction.DictVectorizer()\n",
    "vect.fit(features_pre)\n",
    "print(vect.get_feature_names())\n",
    "result = vect.transform(features_pre)\n",
    "print(result)\n",
    "print(result.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bd7ba82f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 进行决策树训练\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(result, np.array(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "baa1af27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['expensive'], dtype=object)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 预测\n",
    "tree.predict([[0,1,0,0,0,8]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270bd7f7",
   "metadata": {},
   "source": [
    "### 文本特征抽取CountVectorizer\n",
    "用于文章分类等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "46748359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['happy', 'is', 'it', 'life', 'love', 'makes', 'me', 'need', 'python', 'short']\n",
      "  (0, 3)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 9)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 8)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 0)\t1\n",
      "[[0 1 0 1 0 0 0 1 1 1]\n",
      " [1 0 1 0 1 1 1 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "text1 = 'life is short, i need python'\n",
    "text2 = 'i love python, it makes me happy'\n",
    "vect = CountVectorizer()\n",
    "words = vect.fit_transform([text1,text2])\n",
    "print(vect.get_feature_names())\n",
    "print(words)\n",
    "print(words.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca82d639",
   "metadata": {},
   "source": [
    "#### 对于中文的特征抽取，因为CountVectorizer只能识别两个空字符串之前的字符，所以要先对中文字符串进行处理，这里用到jieba包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "05e61795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c\n",
      "d\n",
      "e\n",
      "--------------------\n",
      "c\n",
      "d\n",
      "e\n"
     ]
    }
   ],
   "source": [
    "# 准备-filter函数\n",
    "filter_ = [\"a\",\"b\"]\n",
    "list_ = [\"a\",\"b\",\"c\",\"d\",\"e\"]\n",
    "list1_ = \"abcde\"\n",
    "for i in filter(lambda x: x not in filter_, list_):\n",
    "    print(i)\n",
    "    \n",
    "print(\"-\"*20)\n",
    "\n",
    "for i in filter(lambda x: x not in filter_, list1_):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9550279e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['李雅婷', '说', '她', '不想', '努力', '了', '我', '觉得', '她', '傻傻的']\n",
      "李雅婷 说 她 不想 努力 了 我 觉得 她 傻傻的\n"
     ]
    }
   ],
   "source": [
    "# 准备-jieba的使用\n",
    "word = \"李雅婷说她不想努力了，我觉得她傻傻的\"\n",
    "word_jieba = list(jieba.cut(word))\n",
    "# 符号对特征数据训练时无效的，所以要去除标点符号\n",
    "# 先创建一个列表，把需要过滤的符号都放进去\n",
    "biaodian = [\"。\", \"，\"]\n",
    "# 过滤\n",
    "list_ = list(filter(lambda x: x not in biaodian, word_jieba))\n",
    "print(list_)\n",
    "# 转为CountVectorizer能识别的格式\n",
    "words = \" \".join(list_)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9de7fd84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['生 的 旅途 是 充满 艰险 、 蜿蜒 曲折 的 面对 他 与 他 挑战 需要 我们 内心深处 的 勇气 而 勇气 的 赋予 者 -- 对 个人成长 影响 最大 的 一个 人 这个 人 给予 了 我们 挑战 自己 、 战胜 强敌 的 决心 是 我们 人生 中 最 重要 的 精神支柱',\n",
       " '对 我 影响 最大 的 一个 人 是 隐形 的 翅膀 中 的 女主角 一个 失去 了 双臂 的 青春 女孩 一个 与 命运 搏斗 的 女孩',\n",
       " '对 我 影响 最大 的 一个 人 是 隐形 的 翅膀 中 的 女主角 一个 失去 了 双臂 的 青春 女孩 一个 与 命运 搏斗 的 女孩']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# countvectorizer的在中文中的应用\n",
    "word1 = \"生的旅途是充满艰险、蜿蜒曲折的。面对他，与他挑战需要我们内心深处的勇气。而勇气的赋予者--对个人成长影响最大的一个人。这个人给予了我们挑战自己、战胜强敌的决心，是我们人生中最重要的精神支柱。\"\n",
    "word2 = \"对我影响最大的一个人是《隐形的翅膀》中的女主角，一个失去了双臂的青春女孩，一个与命运搏斗的女孩。\"\n",
    "word3 = \"对我影响最大的一个人是《隐形的翅膀》中的女主角，一个失去了双臂的青春女孩，一个与命运搏斗的女孩。\"\n",
    "words = [word1,word2,word3]\n",
    "words_new = []\n",
    "biaodian=[\"。\",\"，\",\"《\",\"》\"]\n",
    "for word in words:\n",
    "    words_new.append(\" \".join(list(filter(lambda x: x not in biaodian, jieba.cut(word)))))\n",
    "words_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c77d2e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['一个', '个人成长', '人生', '充满', '内心深处', '决心', '勇气', '双臂', '命运', '失去', '女主角', '女孩', '强敌', '影响', '我们', '战胜', '挑战', '搏斗', '旅途', '曲折', '最大', '精神支柱', '给予', '翅膀', '自己', '艰险', '蜿蜒', '赋予', '这个', '重要', '隐形', '需要', '青春', '面对']\n",
      "[[1 1 1 1 1 1 2 0 0 0 0 0 1 1 3 1 2 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1]\n",
      " [3 0 0 0 0 0 0 1 1 1 1 2 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0]\n",
      " [3 0 0 0 0 0 0 1 1 1 1 2 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer()\n",
    "vect.fit(words_new)\n",
    "print(vect.get_feature_names())\n",
    "\n",
    "result = vect.transform(words_new)\n",
    "print(result.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853d224b",
   "metadata": {},
   "source": [
    "## 中文特征抽取实战"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "bf73dad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入文件，生成features和target\n",
    "with open(\"data/Chinese_vect/paper.txt\",\"r\",encoding=\"utf-8\") as f:\n",
    "    paper=f.read()\n",
    "    \n",
    "# 引入re模块对paper进行分割\n",
    "import re\n",
    "features = paper_list = re.split(r\"\\n\\n+\",paper)\n",
    "\n",
    "# target列表，0代表励志累，1代表科技类\n",
    "target =[0 for _ in range(10)] + [1 for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "338bb08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对中文features进行处理，整理成countvectorizer能识别的形式\n",
    "biaodian=[\"一一\",\"pl12\",\"pl15\",\"、\",\"-----\",\"·\",\"----\",\"— —\",\"…\",\"，\",\"。\",\"《\",\"》\",\"……\",\"！\",\"“\",\"“\",\"（\",\"）\",\"：\",\"；\",\"？\",\"”\",\"*\",\"!\",\"?\",\",\",\"\\n\",\"\\u3000\",\",\",\"\\t\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"]\n",
    "features=[]\n",
    "for paper in paper_list:\n",
    "    features.append(\" \".join(list(filter(lambda x: x not in biaodian, jieba.cut(paper)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "f101b18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100', '110', '177', '1997', '20', '2020', '21', '35', '45', '5g', '66', '95', 'dsi', '一万多', '一下', '一两个', '一个', '一个个', '一举', '一些']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 1, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 特征抽取\n",
    "vect = CountVectorizer()\n",
    "features = vect.fit_transform(features)\n",
    "print(vect.get_feature_names()[0:20])\n",
    "features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "22285d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割\n",
    "x_train,x_test,y_train,y_test = train_test_split(features,target,train_size=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "bb24533f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinomial = MultinomialNB()\n",
    "multinomial.fit(x_train,y_train)\n",
    "multinomial.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "92395ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测: [0 0 1 1]\n",
      "评分: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       励志类文章       1.00      1.00      1.00         2\n",
      "       科技类文章       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 随便抽取文章进行识别\n",
    "paper1 = \"风月如流，光阴迈着一成不变的脚步，不疾不缓地走着，走过一个个春秋冬夏，走过一个个月阴日晴。蓦然回首，远逝的日子仿佛晃动的万花筒，不经意间摇晃出一个个无法模仿的图案，那一次次的聚散与悲欢都成绝版。于是我知道，青春是一列单程客车，不能返回也没有驿站。晨钟暮鼓，催促我扬起远航的风帆，心却如一枚留恋故枝的叶子，踟蹰在昨日的风中，依依难从我做起舍。也知道不该贻误行程，却又无法摆脱情感的羁绊，无法将曾经有过的一切尘封在记忆的城堡中，重生日锁紧，每天走过日落月升，仿佛伫立于清澈的河流中，那清清的河水就是我拥有而且仅仅拥有一次的生命啊，我却有太多的时候是立在水中，任凭上游的水流过我之后成为下游的水，任凭未来流经我的现在成为过去，我却因为过分沉迷于昨天而失去了今天和明天，于是一无所有。常常想象，当春华和秋实都成为历史之后，我披满头雪花坐在昨天的记忆中，咀嚼脸上每一道沟壑所深藏的故事，该是一种怎样的心境!本该是懂得很多便相信得很少，却依然一次次为“狼来了”的戏言所惑;本该是走过冬天更钟情于春天，却依然留恋“雪孩子”的童话。走过的路程似乎是一个圆，长途跋涉后又回到起点。于是很多时候是在做相同的事，就是寻找目标。曾经在幽幽暗暗中苦思冥想，终于破译出原来最简单的草枯草荣就是一种玄奥，那是生命的直观教具：花只能红一次，草只能绿一年。逝者如斯，如烟的往事都已随季风飘零，何必苦苦地追寻与回忆。青春的列车载客无数，没有人能预料沿途的遭遇，也没有人能重回自己上车的起点。既然已经别无选择，就让我在时间的钢轨上碾碎曾经有过的失意与如意，然后推开门窗，沐着新鲜的空气与阳光，迎接崭新的行程。因为我已经知道，青春是一列单程客车，不能返回也没有驿站。\"\n",
    "paper2 = \"那些青春，已悄然老去;那些梦想，你可曾记得?青春，只一个很美的词，但又不知道它没在哪里。或许是因为年轻，所以享有青春。或许是因为年轻，才会对所有怀揣幻想。有些时候，曾幻想现实是多么美好，真想一下子融入现实生活中去感受一切。校园里的青涩年华，拥有美好的青春时光。我是幸福的，幸福到感受不到现实的残酷。而今，忽然回头，一些斑驳的记忆已支离破碎，再也拼凑不回。在我们的生命中，青春也悄然老去，离我们越拉越远，模糊了我们的实现，忘记了前路的方向。青春，是一个残酷的词。但又不明白它为何残酷。或许是因为成熟，所以知道残酷。或许是因为成熟，才会慢慢遗忘了青春。偶尔回头看看，却发现自己已偏离了轨道，和现实越走越近了，以至于丢失了那份纯真。梦想，似乎很重、很重。压得我们快要喘不过气。有时候甚至想丢开它，独自去一个无人知晓的地方。不知不觉中，梦想也随着我们长大了，越长大就越重。我们肩膀上的压力越大，脚步就不会变慢。这个季节，很快就会离我们而去，只是我们还停留在原地，依然守护着那些遥不可及的梦想。曾几何时，梦想拉近了我们与现实的距离，把我们一下子打回了原形。我们渐渐地，和现实越走越近。而在残酷的现实中，梦被扭曲了，变味儿了。无意之中，它渐渐偏离了我们。我们可以选择做一个自私的人，哪怕是一无所有。然后有一天突然发现，自己也变得很现实。于是只好重新拾起那些残缺的梦想。那些陈腐的过往，如今已随风即逝。雨过之后，我们看见的不是阳光，不是彩虹，而已灰色的天空，没有一丝色彩。繁花过后，青春散尽。那些要不可以的梦想，随着一阵微风而远行，不留一丝足迹。而在我们心底，仍然残留着一些破碎的痕迹。常说：我们有资本，因为我们还年轻。可是青春经不起肆意挥霍，也许有一天梦想会随着时间的流逝而不见。有一天，我们终将会慢慢老去。生活中，我们不应该是感伤的。忧伤和快乐事不过是一种形式。岁月带走了青春，别人看似美好的青春，但没有多少实际意义。奋斗，为时不晚，因为心中有梦。纵然年华不再，但是心中的斗志永不磨灭。它就像是一个火种，只要心底的那一丝温度不灭，它就会燃烧，越烧越旺。让我们接受过去，接受自己，带上梦想，悄悄地开始一段自己的旅程……\"\n",
    "paper3 = \"四十年砥砺奋进，七十年长歌未央，一百年精神永存，时至今日，在五四爱国旗帜的引领下，中国人进步图存、科学救国。中国梦以一丝微光到今日的无限光明，离不开一代又一代人的接力传承，作为当代青年，我们承载着中华民族复兴之重任，科学兴国，吾辈担当。科学兴国，是历史的启迪。那时我们沉浸于“天朝上国”的美梦而不自知，殊不知，工业革命后科技发展迅速的西方文明已逐渐将我们甩在身后。当西方列强用坚船利炮轰开中国紧锁已久的大门，这片繁华千年的大地上留下了无尽的血泪与伤痕。近百年屈辱史，凝聚了中华民族无力的抗争与挣扎，终将沉睡的民族唤醒。鲁迅说：“我们将火药制成了烟花炮竹，可西方却将其制成火炮。”科学的停滞与落后，是造成我国国力落后于西方的根本原因，五四运动高举科学救国的旗帜，将中国唤醒。科学兴国，是时代的感召。我们关注今日之中国，经济飞速发展，已跃居世界前列。林达曾言：“刺破水面的锐利冰封，它也许只露出一角。”我们不仅仅要看到经济增长的高速度，更要看到速度之下，能源驱动型产业面临着资源枯竭、环境污染;劳动力密集型产业面临着人口红利衰退，增长乏力;高科技产业核心科技受制于发达国家的窘境。无论经济之花多么繁荣美丽，若没有科技作为支撑，中国经济持续发展，中国之梦的实现又何以为继?我们必须重新审视这个时代，这是一个科技飞速发展，日新月异的时代，科学技术作为第一生产力，已在无数实践中被证明，迈入知识经济时代，国之兴盛当以科学兴国、科学创新为先。科学兴国，是吾辈之担当。挪威戏剧家易卜生说过：“社会如同一条船，每个人都要做好掌舵的准备。”而我们要做的，则是要做好接力传承中华科学兴国之使命。我们可以看到，先辈们已为我们迈出了坚实一步，从五四科学救国的大旗，到“八六三”计划，科教兴国战略，再到神舟系列飞船升天，杂交水稻亩产再度突破。我看到，从邓稼先的隐姓埋名，到屠呦呦永不放弃，再到南仁东的一生坚守，无数前辈的努力，造就了今日蓬勃发展之中国。而我辈当承其志，将中国梦以高铁般速度持续推进。这是一个充满希望的国度，这是一个生机勃勃的时代，领袖在新年贺词中说：“我们都在努力奔跑，我们都是追梦人。”愿当代青年同胞们用科学力量武装自己，接力传承中华复兴之梦!\"\n",
    "paper4 = \"开学第一课，一听到这个名字，每一个小学生都会记忆犹新，而他也整整陪伴了我5年。今年的主题是五星红旗，我为你自豪！说到五星红旗，有的人就会想到战争时期战士们的英勇牺牲；有的人就会想到党中央的正确领导；还有的人会想到中国刚成立百废待兴的时刻；而我想到的是我们国家日新月异的科技发展。这70年里，我国的科学技术从落后到了前三，从一无所有到世界领先，今年上半年，在第四次工业革命中，我们实现了弯道超车。中国的科技正在飞速发展，新四大发明正在影响着世界。在开学第一课里，那些大哥哥大姐姐手中的救援机器人成功实现了3分钟的迷你救援。看到他们将拼好的小机器人通过ipad操控就可以操控自如。尽管路上有很多障碍物，但是这些机器人靠这搭桥车通过断桥，靠推作文https://Www.ZuoWEn8.Com/土车把石头推到一边，靠机器爪子把一大块的墙移开救出人，然后送进车里飞快的去医院。我们都知道，当灾难降临后的72小时是救援的最好时机也就是3天，由于是迷你实验的成功也可以预测出我们在真实情况下也可以在3天之内救出被困者。我们不光有先进的救援设备，我们还有探索太空的神器——玉兔，当那个小家伙出现在舞台上的时候，我的眼睛都看直了。我也很想亲自到现场去看看，亲自操作一下小机器人，亲自和小玉兔进行互动……而更值得我学习的就是这些伟大的科技的背后，那个伟大的中国梦。所以作为巩华追梦少年的我要从新学期开始就努力严格要求自己，写一手好字，练就一副好口才，真正把爱国之志变成报国之行。今天为振兴中华而勤奋学习，明天为创造祖国辉煌未来贡献自己的力量！\"\n",
    "papers=[paper1,paper2,paper3,paper4]\n",
    "papers_target=[0,0,1,1]\n",
    "#特征抽取\n",
    "features=[]\n",
    "for paper in papers:\n",
    "    features.append(\" \".join(list(filter(lambda x: x not in biaodian, jieba.cut(paper)))))\n",
    "features = vect.transform(features)\n",
    "#评分\n",
    "print(\"预测:\",multinomial.predict(features))\n",
    "print(\"评分:\",multinomial.score(features,papers_target))\n",
    "print(classification_report(papers_target,multinomial.predict(features),labels=[0,1],target_names=[\"励志类文章\",\"科技类文章\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101edd10",
   "metadata": {},
   "source": [
    "## TFIDF特征抽取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "dee16f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.0380317  0.0380317  0.0380317 ]\n",
      " [0.06018309 0.06018309 0.06018309 ... 0.         0.         0.        ]]\n",
      "['70', '72', 'com', 'https', 'ipad', 'www', 'zuowen8', '一下', '一下子', '一下子打', '一丝', '一个', '一个个', '一些', '一代', '一代人', '一切', '一列', '一副', '一大块', '一天', '一年', '一成不变', '一手', '一无所有', '一条', '一枚', '一次', '一次次', '一步', '一段', '一生', '一百年', '一种', '一角', '一边', '一道', '一阵', '七十年', '万花筒', '上半年', '上游', '上车', '下游', '不仅仅', '不会', '不光', '不再', '不到', '不回', '不是', '不留', '不疾不缓', '不知不觉', '不经意', '不能', '不见', '不该', '不过', '世界', '世界领先', '丢失', '丢开', '严格要求', '中华', '中华民族', '中国', '中说', '为何', '为先', '为时不晚', '主题', '之下', '之内', '之后', '之志', '之梦', '之花', '乏力', '也许', '于是', '互动', '五四', '五四运动', '五星红旗', '产业', '亩产', '享有', '亲自', '人会', '人口', '人能', '仅仅', '今天', '今年', '今日', '仍然', '从我做起', '他们', '以至于', '任凭', '仿佛', '伟大', '传承', '伤痕', '伫立', '似乎', '但是', '何以', '何必', '作为', '作文', '使命', '依依', '依然', '值得', '偏离', '做好', '停滞', '停留', '偶尔', '催促', '像是', '充满希望', '先辈', '先进', '光明', '光阴', '党中央', '六三', '关注', '兴国', '兴盛', '再也', '再到', '再度', '冬夏', '冬天', '冰封', '准备', '凝聚', '出现', '分钟', '列强', '列车', '刚成立', '创新', '创造', '别人', '别无选择', '制成', '刺破', '前列', '前路', '前辈', '力量', '努力', '劳动力', '勤奋学习', '医院', '千年', '升天', '单程', '南仁东', '即逝', '历史', '压力', '原地', '原形', '原来', '发展', '发现', '发现自己', '发达国家', '受制于', '变味儿', '变得', '变慢', '变成', '口才', '只好', '只是', '只能', '只要', '可以', '可是', '叶子', '同胞们', '名字', '听到', '启迪', '吾辈', '咀嚼', '哥哥', '哪怕', '哪里', '唤醒', '四十年', '四大发明', '回到', '回头', '回忆', '因为', '国之', '国力', '国家', '国度', '图存', '图案', '地上', '地方', '坐在', '坚守', '坚实', '坚船利炮', '城堡', '增长', '复兴', '多么', '多少', '大旗', '大门', '天朝', '天空', '太空', '失去', '失意', '奋斗', '奋进', '奔跑', '好字', '如今', '如同', '如意', '如流', '如烟', '姐姐', '季节', '季风', '学习', '学期开始', '孩子', '守护', '实现', '实践', '实际意义', '实验', '审视', '客车', '密集型', '寻找', '小学生', '小家伙', '小时', '少年', '尘封', '就是', '就让', '尽管', '屈辱', '岁月', '崭新', '工业革命', '巩华', '已久', '已经', '带上', '带走', '常常', '常说', '年华', '年轻', '年里', '幸福', '幻想', '幽幽暗暗', '应该', '开始', '开学', '引领', '弯道', '当代', '当以', '当承其志', '形式', '彩虹', '影响', '往事', '很多', '很少', '很快', '微光', '微风', '心中', '心境', '心底', '必须', '忘记', '忧伤', '快乐', '快要', '忽然', '怀揣', '怎样', '悄悄地', '悄然', '悲欢', '情感', '想到', '想象', '感伤', '感受', '感召', '慢慢', '懂得', '戏剧家', '戏言', '成为', '成功', '成熟', '我们', '我国', '我辈', '或许', '战争', '战士', '战略', '所以', '所惑', '所有', '手中', '扬起', '扭曲', '承载', '抗争', '报国', '担当', '拉近', '拥有', '拼凑', '拼好', '拾起', '持续', '挣扎', '挪威', '振兴中华', '掌舵', '探索', '接力', '接受', '推开', '推进', '搭桥', '摆脱', '摇晃', '操作', '操控', '支撑', '支离破碎', '放弃', '故事', '故枝', '救出', '救国', '救援', '散尽', '整整', '文明', '斑驳', '斗志', '断桥', '新年贺词', '新鲜', '方向', '旅程', '旗帜', '无人知晓', '无力', '无尽', '无意之中', '无数', '无法', '无论', '无限', '既然', '日子', '日新月异', '日落', '时代', '时候', '时光', '时刻', '时期', '时机', '时至今日', '时间', '明天', '明白', '易卜生', '春华', '春天', '春秋', '昨天', '昨日', '是因为', '晃动', '晨钟暮鼓', '更要', '曾几何时', '曾经', '曾言', '最好', '有些', '有时候', '有过', '未央', '未来', '本该', '机器', '机器人', '杂交', '林达', '枯竭', '枯草', '校园', '核心', '根本原因', '梦以', '梦想', '模仿', '模糊', '正在', '正确', '武装', '殊不知', '残留', '残缺', '残酷', '每个', '每天', '民族', '水中', '水流', '水稻', '水面', '永不', '永不磨灭', '永存', '沉浸于', '沉睡', '沉迷于', '沟壑', '没有', '河水', '河流', '沿途', '流经', '流逝', '深藏', '清清的', '清澈', '渐渐', '温度', '满头', '火炮', '火种', '火药', '灰色', '灾难', '炮竹', '烟花', '然后', '燃烧', '爪子', '爱国', '牺牲', '独自', '狼来了', '玄奥', '玉兔', '环境污染', '现在', '现场', '现实', '现实生活', '甚至', '生产力', '生命', '生日', '生机勃勃', '生活', '由于', '留下', '留恋', '痕迹', '百年', '百废待兴', '目标', '直观教具', '相信', '相同', '看似', '看到', '看直', '看看', '看见', '真实情况', '真想', '真正', '眼睛', '知识经济', '知道', '石头', '砥砺', '破碎', '破译', '碾碎', '社会', '祖国', '神器', '神舟', '离不开', '秋实', '科学', '科学技术', '科技', '科教兴国', '移开', '空气', '突然', '突破', '窘境', '童话', '第一', '第一课', '第四次', '简单', '精神', '系列', '紧锁', '繁华', '繁花', '繁荣', '红利', '纯真', '纵然', '练就', '终于', '终将', '经不起', '经济', '绝版', '羁绊', '美丽', '美好', '美梦', '美的', '老去', '而且', '而今', '而已', '聚散', '肆意挥霍', '肩膀', '背后', '能源', '脚步', '脸上', '自如', '自己', '自知', '自私', '自豪', '舞台', '色彩', '苦思冥想', '苦苦', '英勇', '落后', '蓦然回首', '蓬勃发展', '融入', '血泪', '行程', '衰退', '被困', '西方', '计划', '记得', '记忆', '记忆犹新', '设备', '证明', '该是', '贡献', '贻误', '资本', '资源', '走过', '起点', '超车', '越大', '越拉越', '越旺', '越烧', '越近', '越重', '足迹', '跃居', '距离', '路上', '路程', '踟蹰', '身后', '车把', '车里', '轨道', '轰开', '载客', '辉煌', '迅速', '过分', '过去', '过后', '过往', '迈入', '迈出', '迈着', '迎接', '返回', '还有', '这个', '这些', '这是', '这片', '进步', '进行', '远航', '远行', '远逝', '迷你', '追寻', '追梦', '追梦人', '选择', '逐渐', '通过', '逝者如斯', '速度', '造就', '造成', '遗忘', '遥不可及', '遭遇', '邓稼先', '那个', '那些', '那份', '那时', '重任', '重回', '重新', '钟情', '钢轨', '锁紧', '锐利', '长大', '长歌', '长途跋涉', '门窗', '阳光', '阴日', '陈腐', '降临', '陪伴', '随着', '随风', '隐姓埋名', '障碍物', '雨过', '雪花', '露出', '青年', '青春', '青涩', '面临', '预料', '预测出', '领导', '领袖', '风中', '风帆', '风月', '飘零', '飞快', '飞船', '飞速发展', '驱动', '驿站', '高举', '高科技', '高速度', '高铁', '鲁迅']\n"
     ]
    }
   ],
   "source": [
    "paper1 = \"风月如流，光阴迈着一成不变的脚步，不疾不缓地走着，走过一个个春秋冬夏，走过一个个月阴日晴。蓦然回首，远逝的日子仿佛晃动的万花筒，不经意间摇晃出一个个无法模仿的图案，那一次次的聚散与悲欢都成绝版。于是我知道，青春是一列单程客车，不能返回也没有驿站。晨钟暮鼓，催促我扬起远航的风帆，心却如一枚留恋故枝的叶子，踟蹰在昨日的风中，依依难从我做起舍。也知道不该贻误行程，却又无法摆脱情感的羁绊，无法将曾经有过的一切尘封在记忆的城堡中，重生日锁紧，每天走过日落月升，仿佛伫立于清澈的河流中，那清清的河水就是我拥有而且仅仅拥有一次的生命啊，我却有太多的时候是立在水中，任凭上游的水流过我之后成为下游的水，任凭未来流经我的现在成为过去，我却因为过分沉迷于昨天而失去了今天和明天，于是一无所有。常常想象，当春华和秋实都成为历史之后，我披满头雪花坐在昨天的记忆中，咀嚼脸上每一道沟壑所深藏的故事，该是一种怎样的心境!本该是懂得很多便相信得很少，却依然一次次为“狼来了”的戏言所惑;本该是走过冬天更钟情于春天，却依然留恋“雪孩子”的童话。走过的路程似乎是一个圆，长途跋涉后又回到起点。于是很多时候是在做相同的事，就是寻找目标。曾经在幽幽暗暗中苦思冥想，终于破译出原来最简单的草枯草荣就是一种玄奥，那是生命的直观教具：花只能红一次，草只能绿一年。逝者如斯，如烟的往事都已随季风飘零，何必苦苦地追寻与回忆。青春的列车载客无数，没有人能预料沿途的遭遇，也没有人能重回自己上车的起点。既然已经别无选择，就让我在时间的钢轨上碾碎曾经有过的失意与如意，然后推开门窗，沐着新鲜的空气与阳光，迎接崭新的行程。因为我已经知道，青春是一列单程客车，不能返回也没有驿站。\"\n",
    "paper2 = \"那些青春，已悄然老去;那些梦想，你可曾记得?青春，只一个很美的词，但又不知道它没在哪里。或许是因为年轻，所以享有青春。或许是因为年轻，才会对所有怀揣幻想。有些时候，曾幻想现实是多么美好，真想一下子融入现实生活中去感受一切。校园里的青涩年华，拥有美好的青春时光。我是幸福的，幸福到感受不到现实的残酷。而今，忽然回头，一些斑驳的记忆已支离破碎，再也拼凑不回。在我们的生命中，青春也悄然老去，离我们越拉越远，模糊了我们的实现，忘记了前路的方向。青春，是一个残酷的词。但又不明白它为何残酷。或许是因为成熟，所以知道残酷。或许是因为成熟，才会慢慢遗忘了青春。偶尔回头看看，却发现自己已偏离了轨道，和现实越走越近了，以至于丢失了那份纯真。梦想，似乎很重、很重。压得我们快要喘不过气。有时候甚至想丢开它，独自去一个无人知晓的地方。不知不觉中，梦想也随着我们长大了，越长大就越重。我们肩膀上的压力越大，脚步就不会变慢。这个季节，很快就会离我们而去，只是我们还停留在原地，依然守护着那些遥不可及的梦想。曾几何时，梦想拉近了我们与现实的距离，把我们一下子打回了原形。我们渐渐地，和现实越走越近。而在残酷的现实中，梦被扭曲了，变味儿了。无意之中，它渐渐偏离了我们。我们可以选择做一个自私的人，哪怕是一无所有。然后有一天突然发现，自己也变得很现实。于是只好重新拾起那些残缺的梦想。那些陈腐的过往，如今已随风即逝。雨过之后，我们看见的不是阳光，不是彩虹，而已灰色的天空，没有一丝色彩。繁花过后，青春散尽。那些要不可以的梦想，随着一阵微风而远行，不留一丝足迹。而在我们心底，仍然残留着一些破碎的痕迹。常说：我们有资本，因为我们还年轻。可是青春经不起肆意挥霍，也许有一天梦想会随着时间的流逝而不见。有一天，我们终将会慢慢老去。生活中，我们不应该是感伤的。忧伤和快乐事不过是一种形式。岁月带走了青春，别人看似美好的青春，但没有多少实际意义。奋斗，为时不晚，因为心中有梦。纵然年华不再，但是心中的斗志永不磨灭。它就像是一个火种，只要心底的那一丝温度不灭，它就会燃烧，越烧越旺。让我们接受过去，接受自己，带上梦想，悄悄地开始一段自己的旅程……\"\n",
    "paper3 = \"四十年砥砺奋进，七十年长歌未央，一百年精神永存，时至今日，在五四爱国旗帜的引领下，中国人进步图存、科学救国。中国梦以一丝微光到今日的无限光明，离不开一代又一代人的接力传承，作为当代青年，我们承载着中华民族复兴之重任，科学兴国，吾辈担当。科学兴国，是历史的启迪。那时我们沉浸于“天朝上国”的美梦而不自知，殊不知，工业革命后科技发展迅速的西方文明已逐渐将我们甩在身后。当西方列强用坚船利炮轰开中国紧锁已久的大门，这片繁华千年的大地上留下了无尽的血泪与伤痕。近百年屈辱史，凝聚了中华民族无力的抗争与挣扎，终将沉睡的民族唤醒。鲁迅说：“我们将火药制成了烟花炮竹，可西方却将其制成火炮。”科学的停滞与落后，是造成我国国力落后于西方的根本原因，五四运动高举科学救国的旗帜，将中国唤醒。科学兴国，是时代的感召。我们关注今日之中国，经济飞速发展，已跃居世界前列。林达曾言：“刺破水面的锐利冰封，它也许只露出一角。”我们不仅仅要看到经济增长的高速度，更要看到速度之下，能源驱动型产业面临着资源枯竭、环境污染;劳动力密集型产业面临着人口红利衰退，增长乏力;高科技产业核心科技受制于发达国家的窘境。无论经济之花多么繁荣美丽，若没有科技作为支撑，中国经济持续发展，中国之梦的实现又何以为继?我们必须重新审视这个时代，这是一个科技飞速发展，日新月异的时代，科学技术作为第一生产力，已在无数实践中被证明，迈入知识经济时代，国之兴盛当以科学兴国、科学创新为先。科学兴国，是吾辈之担当。挪威戏剧家易卜生说过：“社会如同一条船，每个人都要做好掌舵的准备。”而我们要做的，则是要做好接力传承中华科学兴国之使命。我们可以看到，先辈们已为我们迈出了坚实一步，从五四科学救国的大旗，到“八六三”计划，科教兴国战略，再到神舟系列飞船升天，杂交水稻亩产再度突破。我看到，从邓稼先的隐姓埋名，到屠呦呦永不放弃，再到南仁东的一生坚守，无数前辈的努力，造就了今日蓬勃发展之中国。而我辈当承其志，将中国梦以高铁般速度持续推进。这是一个充满希望的国度，这是一个生机勃勃的时代，领袖在新年贺词中说：“我们都在努力奔跑，我们都是追梦人。”愿当代青年同胞们用科学力量武装自己，接力传承中华复兴之梦!\"\n",
    "paper4 = \"开学第一课，一听到这个名字，每一个小学生都会记忆犹新，而他也整整陪伴了我5年。今年的主题是五星红旗，我为你自豪！说到五星红旗，有的人就会想到战争时期战士们的英勇牺牲；有的人就会想到党中央的正确领导；还有的人会想到中国刚成立百废待兴的时刻；而我想到的是我们国家日新月异的科技发展。这70年里，我国的科学技术从落后到了前三，从一无所有到世界领先，今年上半年，在第四次工业革命中，我们实现了弯道超车。中国的科技正在飞速发展，新四大发明正在影响着世界。在开学第一课里，那些大哥哥大姐姐手中的救援机器人成功实现了3分钟的迷你救援。看到他们将拼好的小机器人通过ipad操控就可以操控自如。尽管路上有很多障碍物，但是这些机器人靠这搭桥车通过断桥，靠推作文https://Www.ZuoWEn8.Com/土车把石头推到一边，靠机器爪子把一大块的墙移开救出人，然后送进车里飞快的去医院。我们都知道，当灾难降临后的72小时是救援的最好时机也就是3天，由于是迷你实验的成功也可以预测出我们在真实情况下也可以在3天之内救出被困者。我们不光有先进的救援设备，我们还有探索太空的神器——玉兔，当那个小家伙出现在舞台上的时候，我的眼睛都看直了。我也很想亲自到现场去看看，亲自操作一下小机器人，亲自和小玉兔进行互动……而更值得我学习的就是这些伟大的科技的背后，那个伟大的中国梦。所以作为巩华追梦少年的我要从新学期开始就努力严格要求自己，写一手好字，练就一副好口才，真正把爱国之志变成报国之行。今天为振兴中华而勤奋学习，明天为创造祖国辉煌未来贡献自己的力量！\"\n",
    "papers=[paper1,paper2,paper3,paper4]\n",
    "#特征抽取\n",
    "features=[]\n",
    "for paper in papers:\n",
    "    features.append(\" \".join(list(filter(lambda x: x not in biaodian, jieba.cut(paper)))))\n",
    "tfidf = TfidfVectorizer()\n",
    "features = tfidf.fit_transform(features)\n",
    "print(features.toarray())\n",
    "print(tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "58e931b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf案例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "8b4ca93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'filenames', 'target', 'target_names']"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroup = fetch_20newsgroups(data_home=\"./data\")\n",
    "dir(newsgroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "71920cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征抽取\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "features = tfidf_vect.fit_transform(newsgroup.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "76e98db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(features, newsgroup.target, train_size=0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "f57f6ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8604240282685512"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练\n",
    "multi = MultinomialNB()\n",
    "multi.fit(x_train,y_train)\n",
    "multi.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19134f59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
